{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-12T08:39:01.541266Z",
     "iopub.status.busy": "2022-01-12T08:39:01.540907Z",
     "iopub.status.idle": "2022-01-12T08:39:03.831812Z",
     "shell.execute_reply": "2022-01-12T08:39:03.8309Z",
     "shell.execute_reply.started": "2022-01-12T08:39:01.541227Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random, tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset , DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-12T08:39:03.834529Z",
     "iopub.status.busy": "2022-01-12T08:39:03.833796Z",
     "iopub.status.idle": "2022-01-12T08:39:03.869436Z",
     "shell.execute_reply": "2022-01-12T08:39:03.868574Z",
     "shell.execute_reply.started": "2022-01-12T08:39:03.83448Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../input/deepglobe-land-cover-classification-dataset/metadata.csv')\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-12T08:39:03.871558Z",
     "iopub.status.busy": "2022-01-12T08:39:03.870726Z",
     "iopub.status.idle": "2022-01-12T08:39:03.894342Z",
     "shell.execute_reply": "2022-01-12T08:39:03.893291Z",
     "shell.execute_reply.started": "2022-01-12T08:39:03.871518Z"
    }
   },
   "outputs": [],
   "source": [
    "DATA_DIR = '../input/deepglobe-land-cover-classification-dataset'\n",
    "class_dict = pd.read_csv(os.path.join(DATA_DIR,'class_dict.csv'))\n",
    "class_names = class_dict['name'].tolist()\n",
    "class_rgb_values = class_dict[['r','g','b']].values.tolist()\n",
    "select_class_indices = [class_names.index(cls.lower()) for cls in class_names]\n",
    "select_class_rgb_values = np.array(class_rgb_values)[select_class_indices]\n",
    "print(class_names)\n",
    "select_class_rgb_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-12T08:39:03.896728Z",
     "iopub.status.busy": "2022-01-12T08:39:03.896405Z",
     "iopub.status.idle": "2022-01-12T08:39:03.906737Z",
     "shell.execute_reply": "2022-01-12T08:39:03.906085Z",
     "shell.execute_reply.started": "2022-01-12T08:39:03.896676Z"
    }
   },
   "outputs": [],
   "source": [
    "#helper function for data visualization\n",
    "\n",
    "def visualize(**images):\n",
    "    n_images = len(images)\n",
    "    plt.figure(figsize=(20,8))\n",
    "    for idx , (name,image) in enumerate(images.items()):\n",
    "        plt.subplot(1,n_images,idx+1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.title(name.replace('_',' ').title(),fontsize=20)\n",
    "        plt.imshow(image)\n",
    "        \n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "#perform one hot encoding on the label\n",
    "def one_hot_encode(label,label_values):\n",
    "    \n",
    "    semantic_map = []\n",
    "    for color in label_values:\n",
    "        eq = np.equal(label,color)\n",
    "        class_map = eq.all(axis=-1)\n",
    "        semantic_map.append(class_map)\n",
    "    semantic_map = np.stack(semantic_map,axis=-1)\n",
    "    \n",
    "    return semantic_map\n",
    "\n",
    "#perform reverse one-hot-encoding on labels/preds\n",
    "def reverse_one_hot(image,axis):\n",
    "    \n",
    "    x = np.argmax(image,axis=axis)\n",
    "    return x\n",
    "\n",
    "\n",
    "\n",
    "def color_code_segmentation(image,label_values):\n",
    "    color_codes = label_values\n",
    "    x = color_codes[image.astype('int')]\n",
    "    \n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-12T08:39:03.985459Z",
     "iopub.status.busy": "2022-01-12T08:39:03.984724Z",
     "iopub.status.idle": "2022-01-12T08:39:03.997792Z",
     "shell.execute_reply": "2022-01-12T08:39:03.997104Z",
     "shell.execute_reply.started": "2022-01-12T08:39:03.985415Z"
    }
   },
   "outputs": [],
   "source": [
    "class LandCoverDataset(Dataset):\n",
    "    def __init__(self,is_train_valid,csv_file_path,root_dir,class_rgb_values=None,transform=None):\n",
    "        self.meta_df = pd.read_csv(csv_file_path)\n",
    "        self.meta_df = self.meta_df.dropna(subset=['split'])\n",
    "        self.meta_df = self.meta_df.reset_index(drop=True)\n",
    "        self.root_dir = root_dir\n",
    "        self.class_rgb_values = class_rgb_values\n",
    "        self.is_train_valid = is_train_valid\n",
    "        if is_train_valid == 'train':\n",
    "            img_paths = self.meta_df[(self.meta_df.split == 'train')]['sat_image_path']\n",
    "            mask_paths = self.meta_df[(self.meta_df.split == 'train')]['mask_path']\n",
    "            \n",
    "        elif is_train_valid == 'val':\n",
    "            img_paths = self.meta_df[(self.meta_df.split == 'valid')]['sat_image_path']\n",
    "            \n",
    "        else:\n",
    "            img_paths = self.meta_df[(self.meta_df.split == 'test')]['sat_image_path']\n",
    "        \n",
    "        #print(mask_paths)\n",
    "        self.img_path = [os.path.join(self.root_dir,img_p) for img_p in img_paths]\n",
    "        if is_train_valid == 'train':\n",
    "            self.mask_path = [os.path.join(self.root_dir,mask_p) for mask_p in mask_paths]\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.img_path)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        img_path = self.img_path[idx]\n",
    "        img = cv2.cvtColor(cv2.imread(img_path),cv2.COLOR_BGR2RGB)\n",
    "        if self.is_train_valid == 'train':\n",
    "            mask_path = self.mask_path[idx]\n",
    "            mask = cv2.cvtColor(cv2.imread(mask_path),cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "            #one-hot-encode the mask\n",
    "            mask = one_hot_encode(mask,self.class_rgb_values).astype('float')\n",
    "        \n",
    "            if self.transform is not None:\n",
    "                augmentations = self.transform(image=img,mask=mask)\n",
    "                img = augmentations['image']\n",
    "                mask = augmentations['mask']\n",
    "            \n",
    "            return img , mask\n",
    "        \n",
    "        elif self.is_train_valid == 'test':\n",
    "            if self.transform is not None:\n",
    "                img_ten = self.transform(image=img)\n",
    "                img = img_ten['image']\n",
    "            return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-12T08:39:06.683663Z",
     "iopub.status.busy": "2022-01-12T08:39:06.683226Z",
     "iopub.status.idle": "2022-01-12T08:39:10.826895Z",
     "shell.execute_reply": "2022-01-12T08:39:10.823141Z",
     "shell.execute_reply.started": "2022-01-12T08:39:06.683633Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "dataset = LandCoverDataset('train','../input/deepglobe-land-cover-classification-dataset/metadata.csv','../input/deepglobe-land-cover-classification-dataset',class_rgb_values=select_class_rgb_values)\n",
    "random_idx = random.randint(0,len(dataset)-1)\n",
    "img , mask = dataset[11]\n",
    "\n",
    "print(len(dataset))\n",
    "visualize(\n",
    "    original_image = img,\n",
    "    ground_truth_mask = color_code_segmentation(reverse_one_hot(mask,axis=-1),select_class_rgb_values),\n",
    "    one_hot_encoded_mask = reverse_one_hot(mask,axis=-1)\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-12T08:39:23.443449Z",
     "iopub.status.busy": "2022-01-12T08:39:23.443162Z",
     "iopub.status.idle": "2022-01-12T08:39:24.852409Z",
     "shell.execute_reply": "2022-01-12T08:39:24.85131Z",
     "shell.execute_reply.started": "2022-01-12T08:39:23.443418Z"
    }
   },
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "\n",
    "train_transform = A.Compose([\n",
    "    A.RandomCrop(height=1024,width=1024,always_apply=True),\n",
    "    A.Rotate(limit=35, p=1.0),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.1),\n",
    "    A.Normalize(\n",
    "        mean=[0.0, 0.0, 0.0],\n",
    "        std=[1.0, 1.0, 1.0],\n",
    "        max_pixel_value=255.0,\n",
    "    ),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "test_transform = A.Compose([\n",
    "    A.RandomCrop(height=1024,width=1024),\n",
    "    ToTensorV2(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-12T08:39:28.605457Z",
     "iopub.status.busy": "2022-01-12T08:39:28.60516Z",
     "iopub.status.idle": "2022-01-12T08:39:33.099852Z",
     "shell.execute_reply": "2022-01-12T08:39:33.099203Z",
     "shell.execute_reply.started": "2022-01-12T08:39:28.605426Z"
    }
   },
   "outputs": [],
   "source": [
    "aug_dataset = LandCoverDataset('train','../input/deepglobe-land-cover-classification-dataset/metadata.csv','../input/deepglobe-land-cover-classification-dataset',class_rgb_values=select_class_rgb_values,transform = train_transform)\n",
    "test_dataset = LandCoverDataset('test','../input/deepglobe-land-cover-classification-dataset/metadata.csv','../input/deepglobe-land-cover-classification-dataset/',class_rgb_values=select_class_rgb_values,transform = test_transform)\n",
    "random_idx = random.randint(0,len(dataset)-1)\n",
    "\n",
    "print(len(aug_dataset),len(test_dataset))\n",
    "\n",
    "for idx in range(2):\n",
    "    img , mask = aug_dataset[idx]\n",
    "    img = img.permute(1,2,0).numpy().astype('float32')\n",
    "    mask = mask.numpy().astype('float32')\n",
    "    #print(color_code_segmentation(reverse_one_hot(mask),select_class_rgb_values).shape)\n",
    "    visualize(\n",
    "    original_image = img,\n",
    "    ground_truth_mask = color_code_segmentation(reverse_one_hot(mask,axis=-1),select_class_rgb_values),\n",
    "    one_hot_encoded_mask = reverse_one_hot(mask,axis=-1)\n",
    "    \n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-12T08:39:37.786227Z",
     "iopub.status.busy": "2022-01-12T08:39:37.785564Z",
     "iopub.status.idle": "2022-01-12T08:39:37.802732Z",
     "shell.execute_reply": "2022-01-12T08:39:37.802075Z",
     "shell.execute_reply.started": "2022-01-12T08:39:37.786175Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_size = int(0.9*len(aug_dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "\n",
    "train_data , val_data = random_split(aug_dataset,[train_size,val_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-12T08:30:36.556128Z",
     "iopub.status.busy": "2022-01-12T08:30:36.555766Z",
     "iopub.status.idle": "2022-01-12T08:30:36.562746Z",
     "shell.execute_reply": "2022-01-12T08:30:36.561588Z",
     "shell.execute_reply.started": "2022-01-12T08:30:36.556081Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#loaders\n",
    "train_loader = DataLoader(train_data,batch_size=2,shuffle=True,num_workers=2,pin_memory=True)\n",
    "val_loader = DataLoader(val_data,batch_size=1,num_workers=2,pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-12T08:39:46.700326Z",
     "iopub.status.busy": "2022-01-12T08:39:46.699572Z",
     "iopub.status.idle": "2022-01-12T08:39:46.705911Z",
     "shell.execute_reply": "2022-01-12T08:39:46.705256Z",
     "shell.execute_reply.started": "2022-01-12T08:39:46.700278Z"
    }
   },
   "outputs": [],
   "source": [
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self,in_channels,out_channels):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels,out_channels,3,1,1,bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels,out_channels,3,1,1,bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        return self.conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-12T08:39:47.263422Z",
     "iopub.status.busy": "2022-01-12T08:39:47.262528Z",
     "iopub.status.idle": "2022-01-12T08:39:47.274846Z",
     "shell.execute_reply": "2022-01-12T08:39:47.274154Z",
     "shell.execute_reply.started": "2022-01-12T08:39:47.263367Z"
    }
   },
   "outputs": [],
   "source": [
    "class UNET(nn.Module):\n",
    "    def __init__(self,in_channels=3,out_channels=1,features=[64,128,256,512]):\n",
    "        super().__init__()\n",
    "        self.downs = nn.ModuleList()\n",
    "        self.ups = nn.ModuleList()\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "\n",
    "        for feature in features:\n",
    "            self.downs.append(DoubleConv(in_channels,feature))\n",
    "            in_channels = feature\n",
    "\n",
    "        self.bottleneck = DoubleConv(features[-1],features[-1]*2)\n",
    "\n",
    "        for feature in reversed(features):\n",
    "            self.ups.extend([\n",
    "                           nn.ConvTranspose2d(feature*2,feature,kernel_size=2,stride=2),\n",
    "                           DoubleConv(feature*2,feature)\n",
    "              ])\n",
    "\n",
    "\n",
    "        self.final_conv = nn.Conv2d(features[0],out_channels,kernel_size=1)\n",
    "\n",
    "    def forward(self,x):\n",
    "\n",
    "        skip_connections = []\n",
    "\n",
    "        for down in self.downs:\n",
    "            x = down(x)\n",
    "            skip_connections.append(x)\n",
    "            x = self.pool(x)\n",
    "\n",
    "        x = self.bottleneck(x)\n",
    "\n",
    "        skip_connections = skip_connections[::-1]\n",
    "\n",
    "        for idx in range(0,len(self.ups),2):\n",
    "            x = self.ups[idx](x)\n",
    "            skip_connection = skip_connections[idx//2]\n",
    "            if x.shape != skip_connection.shape:\n",
    "                x = tf.resize(x,size=skip_connection.shape[2:])\n",
    "            concat_skip = torch.cat((skip_connection,x),dim=1)\n",
    "            x = self.ups[idx+1](concat_skip)\n",
    "\n",
    "        return self.final_conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-12T08:09:14.758829Z",
     "iopub.status.busy": "2022-01-12T08:09:14.758346Z",
     "iopub.status.idle": "2022-01-12T08:09:18.220428Z",
     "shell.execute_reply": "2022-01-12T08:09:18.21965Z",
     "shell.execute_reply.started": "2022-01-12T08:09:14.758789Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "device = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "#set hyperparams\n",
    "epochs = 5\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class FocalLoss(nn.modules.loss._WeightedLoss):\n",
    "    def __init__(self, weight=None, gamma=2,reduction='mean'):\n",
    "        super(FocalLoss, self).__init__(weight,reduction=reduction)\n",
    "        self.gamma = gamma\n",
    "        self.weight = weight #weight parameter will act as the alpha parameter to balance class weights\n",
    "\n",
    "    def forward(self, inp, target):\n",
    "\n",
    "        ce_loss = F.cross_entropy(inp, target,reduction=self.reduction,weight=self.weight)\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        focal_loss = ((1 - pt) ** self.gamma * ce_loss).mean()\n",
    "        return focal_loss\n",
    "    \n",
    "    \n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "def mIOU(label, pred, num_classes=7):\n",
    "    pred = F.softmax(pred, dim=1)              \n",
    "    pred = torch.argmax(pred, dim=1).squeeze(1)\n",
    "    iou_list = list()\n",
    "    present_iou_list = list()\n",
    "\n",
    "    pred = pred.view(-1)\n",
    "    label = reverse_one_hot(label.cpu(),axis=1).reshape(-1)\n",
    "    # Note: Following for loop goes from 0 to (num_classes-1)\n",
    "    # and ignore_index is num_classes, thus ignore_index is\n",
    "    # not considered in computation of IoU.\n",
    "    for sem_class in range(num_classes):\n",
    "        pred_inds = (pred == sem_class)\n",
    "        target_inds = (label == sem_class)\n",
    "        if target_inds.long().sum().item() == 0:\n",
    "            iou_now = float('nan')\n",
    "        else: \n",
    "            intersection_now = (pred_inds[target_inds]).long().sum().item()\n",
    "            union_now = pred_inds.long().sum().item() + target_inds.long().sum().item() - intersection_now\n",
    "            iou_now = float(intersection_now) / float(union_now)\n",
    "            present_iou_list.append(iou_now)\n",
    "        iou_list.append(iou_now)\n",
    "    return np.mean(present_iou_list)\n",
    "\n",
    "\n",
    "model = UNET(in_channels=3,out_channels=7).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=3e-4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-12T08:01:12.88527Z",
     "iopub.status.busy": "2022-01-12T08:01:12.885022Z",
     "iopub.status.idle": "2022-01-12T08:01:12.895221Z",
     "shell.execute_reply": "2022-01-12T08:01:12.894329Z",
     "shell.execute_reply.started": "2022-01-12T08:01:12.885242Z"
    }
   },
   "outputs": [],
   "source": [
    "def check_accuracy(loader, model, device=\"cuda\"):\n",
    "    num_correct = 0\n",
    "    num_pixels = 0\n",
    "    dice_score = 0\n",
    "    iou_ = []\n",
    "    iou = 0.0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device)\n",
    "            y = y.permute(0,3,1,2).to(device)\n",
    "            mask_pred = model(x.float())\n",
    "            preds = F.softmax(mask_pred)\n",
    "            preds = (preds > 0.5).float()\n",
    "            #print(preds.shape,y.shape)\n",
    "            num_correct += (preds == y).sum()\n",
    "            num_pixels += torch.numel(preds)\n",
    "            dice_score += (2 * (preds * y).sum()) / (\n",
    "                (preds + y).sum() + 1e-8\n",
    "            )\n",
    "            iou_.append(mIOU(y,mask_pred))\n",
    "            del mask_pred\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "    iou = sum(iou_) / len(iou_)\n",
    "    print(\n",
    "        f\"Got {num_correct}/{num_pixels} with acc {num_correct/num_pixels*100:.2f}\"\n",
    "    )\n",
    "    print(f\"Dice score: {dice_score/len(loader)} , IoU score: {iou} \")\n",
    "    model.train()\n",
    "    \n",
    "    return (dice_score/len(loader)) , iou\n",
    "\n",
    "\n",
    "def save_checkpoint(state, filename=\"my_checkpoint.pth.tar\"):\n",
    "    print(\"=> Saving checkpoint\")\n",
    "    torch.save(state, filename)\n",
    "\n",
    "def load_checkpoint(checkpoint, model):\n",
    "    print(\"=> Loading checkpoint\")\n",
    "    model.load_state_dict(checkpoint[\"state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-12T08:01:18.881054Z",
     "iopub.status.busy": "2022-01-12T08:01:18.880803Z",
     "iopub.status.idle": "2022-01-12T08:01:18.890355Z",
     "shell.execute_reply": "2022-01-12T08:01:18.88943Z",
     "shell.execute_reply.started": "2022-01-12T08:01:18.881028Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_fn(loader,model,optimizer,loss_fn):\n",
    "    \n",
    "    loop = tqdm(loader)\n",
    "    \n",
    "    loss_ = []\n",
    "    \n",
    "    for batch_idx , (data,targets) in enumerate(loop):\n",
    "        \n",
    "        data = data.to(device)\n",
    "        targets = targets.permute(0,3,1,2)\n",
    "        model.train()\n",
    "        #forward\n",
    "        \n",
    "        preds = model(data)\n",
    "        loss = loss_fn(preds,reverse_one_hot(targets.long(),axis=1).to(device))\n",
    "            \n",
    "        #backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        del preds\n",
    "        \n",
    "        \n",
    "        #update tqdm loop\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "        \n",
    "        loss_.append(loss.item())\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "    return sum(loss_) / len(loss_)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-12T05:28:16.786619Z",
     "iopub.status.busy": "2022-01-12T05:28:16.786115Z",
     "iopub.status.idle": "2022-01-12T06:47:24.116068Z",
     "shell.execute_reply": "2022-01-12T06:47:24.115015Z",
     "shell.execute_reply.started": "2022-01-12T05:28:16.786582Z"
    }
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "best_iou_score = 0.0\n",
    "\n",
    "train_log_list , val_log_list = [] , []\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_log , val_log = {} , {}\n",
    "    loss = train_fn(train_loader,model,optimizer,loss_fn)\n",
    "    train_log['loss'] = loss\n",
    "    train_log_list.append(train_log)\n",
    "    \n",
    "\n",
    "    # check accuracy\n",
    "    dice_score , iou = check_accuracy(val_loader, model, device=device)\n",
    "    val_log['dice_score'] = dice_score \n",
    "    val_log['IoU'] = iou\n",
    "    val_log_list.append(val_log)\n",
    "    \n",
    "    if best_iou_score < val_log['IoU']:\n",
    "        best_iou_score < val_log['IoU']\n",
    "        # save model\n",
    "        checkpoint = {\n",
    "            'epoch':epoch,\n",
    "            \"state_dict\": model.state_dict(),\n",
    "            \"optimizer\":optimizer.state_dict(),\n",
    "            \"loss\":loss,\n",
    "            \"dice_score\":dice_score,\n",
    "            \"miou\":iou\n",
    "        }\n",
    "        save_checkpoint(checkpoint)\n",
    "        print('Model saved!')\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-12T08:39:54.502064Z",
     "iopub.status.busy": "2022-01-12T08:39:54.50176Z",
     "iopub.status.idle": "2022-01-12T08:39:59.989465Z",
     "shell.execute_reply": "2022-01-12T08:39:59.988515Z",
     "shell.execute_reply.started": "2022-01-12T08:39:54.502031Z"
    }
   },
   "outputs": [],
   "source": [
    "model = UNET(in_channels=3,out_channels=7)\n",
    "checkpoint = torch.load('../input/checkpoint/my_checkpoint.pth.tar',map_location=torch.device('cpu'))\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "#optimizer.load_state_dict(checkpoint['optimizer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-12T08:40:59.169555Z",
     "iopub.status.busy": "2022-01-12T08:40:59.169224Z",
     "iopub.status.idle": "2022-01-12T08:43:53.74772Z",
     "shell.execute_reply": "2022-01-12T08:43:53.747048Z",
     "shell.execute_reply.started": "2022-01-12T08:40:59.169521Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'random' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-6e0ba4130e0f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0midx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m60\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_dataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'random' is not defined"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    \n",
    "    idx = random.randint(60,100)\n",
    "\n",
    "    image = test_dataset[idx]\n",
    "    x_tensor = image.unsqueeze(0)\n",
    "    # Predict test image\n",
    "    pred_mask = model(x_tensor.float())\n",
    "    pred_mask = pred_mask.detach().squeeze().numpy()\n",
    "    \n",
    "    # Convert pred_mask from `CHW` format to `HWC` format\n",
    "    pred_mask = np.transpose(pred_mask,(1,2,0))\n",
    "    \n",
    "    # Get prediction channel corresponding to foreground\n",
    "    pred_mask = color_code_segmentation(reverse_one_hot(pred_mask,axis=-1), select_class_rgb_values)\n",
    "    \n",
    "    \n",
    "    \n",
    "    visualize(\n",
    "        original_image = image.numpy().transpose(1,2,0),\n",
    "        predicted_mask = pred_mask\n",
    "    )\n",
    "    \n",
    "    del image , pred_mask\n",
    "    \n",
    "    #torch.cuda.empty_cache()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-11T09:43:25.809734Z",
     "iopub.status.busy": "2022-01-11T09:43:25.809087Z",
     "iopub.status.idle": "2022-01-11T09:43:25.818949Z",
     "shell.execute_reply": "2022-01-11T09:43:25.818165Z",
     "shell.execute_reply.started": "2022-01-11T09:43:25.809698Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
